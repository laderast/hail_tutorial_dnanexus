{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03612759-35f5-4519-b777-ef7916f88236",
   "metadata": {},
   "source": [
    "# UKB RAP: From BGEN File to Hail MatrixTable\n",
    "\n",
    "This notebook shows how to load the BGEN files from UKB RAP using the latest version of Hail. Note that the current JupyterLab instance is one version behind. We used this community-developed app from the Lindren Lab to run this: https://github.com/lindgrengroup/hail-on-dnanexus\n",
    "\n",
    "First, we initialize Hail. Note that the BGEN files are lz4 compressed, so we have to specify that in our Spark Context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e04e16-30d0-4858-b11a-507cf1a18349",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/cluster/dnax/jars/dnanexus-api-0.1.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/cluster/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-28 07:29:33.953 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2023-04-28 07:29:34.121 WARN  MetricsReporter:84 - No metrics configured for reporting\n",
      "2023-04-28 07:29:34.123 WARN  LineProtoUsageReporter:48 - Telegraf configurations: url [metrics.push.telegraf.hostport], user [metrics.push.telegraf.user] or password [metrics.push.telegraf.password] missing.\n",
      "2023-04-28 07:29:34.123 WARN  MetricsReporter:117 - metrics.scraping.httpserver.port\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-28 07:29:35.006 WARN  Utils:69 - Service 'sparkDriver' could not bind on port 42000. Attempting port 42001.\n",
      "2023-04-28 07:29:35.775 WARN  Utils:69 - Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 43000. Attempting port 43001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pip-installed Hail requires additional configuration options in Spark referring\n",
      "  to the path to the Hail Python module directory HAIL_DIR,\n",
      "  e.g. /path/to/python/site-packages/hail:\n",
      "    spark.jars=HAIL_DIR/backend/hail-all-spark.jar\n",
      "    spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar\n",
      "    spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.2.0\n",
      "SparkUI available at http://ip-10-60-133-121.eu-west-2.compute.internal:8081\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.108-48fb3a9bae04\n",
      "LOGGING: writing to /home/dnanexus/hail-20230428-0729-0.2.108-48fb3a9bae04.log\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import hail as hl\n",
    "import hail.expr.aggregators as agg\n",
    "import os\n",
    "\n",
    "builder = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .enableHiveSupport()\n",
    "    .config(\"spark.shuffle.mapStatus.compression.codec\", \"lz4\") \n",
    ")\n",
    "spark = builder.getOrCreate()\n",
    "hl.init(sc=spark.sparkContext)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e0009fb-224c-4bc6-881f-0769ae9d66b8",
   "metadata": {},
   "source": [
    "Next, we'll find the files associated with field id 23159. This field corresponds to the Whole Exome Sequencing files in the BGEN format.\n",
    "\n",
    "We first find the file ids using `dxpy.find_data_objects()`. \n",
    "\n",
    "Then we can do a `dx describe` on each of the file ids to get the relevant file information for each file, namely the file name and the folder path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be55db99-93dd-4409-a27a-8783b0b1dffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dxpy, os\n",
    "#import hail as hl\n",
    "import pandas as pd\n",
    "testing = True\n",
    "project_dir = \"/user/tladeras/\"\n",
    "\n",
    "field_id = \"23159\"\n",
    "\n",
    "obj_gen = dxpy.find_data_objects(properties={\"field_id\":field_id}, name=\"*.bgen\", name_mode=\"glob\")\n",
    "\n",
    "id_list = [a[\"id\"] for a in obj_gen]\n",
    "\n",
    "# Grab describe objects for every file id\n",
    "out_describe = [dxpy.bindings.dxdataobject_functions.describe(id) for id in id_list]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2d716b9",
   "metadata": {},
   "source": [
    "Then we'll build a list of file paths using dxFUSE paths. Then we'll process and build the hdfs file paths for indexing, the file name, and the sample file locations. We only will use one of the sample file locations, since all of them are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc559ac6-0d84-4bd3-ab75-a42dc9288d36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make a list of file paths with /mnt/project prepended and using only basename of file\n",
    "dxfuse_list = [f\"file:///mnt/project/\" +  desc[\"folder\"] + \"/\" + os.path.splitext(desc[\"name\"])[0] for desc in out_describe]\n",
    "\n",
    "#grab file name\n",
    "index_list = [f\"\" + desc[\"name\"] for desc in out_describe]\n",
    "#make list of hdfs locations for index\n",
    "hdfs_list = [f\"file:///mnt2/project\" + project_dir + \"index/\" + desc[\"name\"] + \".idx2\" for desc in out_describe]\n",
    "#make list of bgen locations in project storage\n",
    "bgen_list = [dx + \".bgen\" for dx in dxfuse_list]\n",
    "#make list of sample locations in project storage\n",
    "sample_list = [f\"\" + dx + \".sample\" for dx in dxfuse_list]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccf45f3d",
   "metadata": {},
   "source": [
    "In order to transfer files, we'll have to reset some of the environment variables. We'll also mount the project as `/mnt2/project/` with dxFUSE's `-limitedWrite` option. We'll do this by using this script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac4580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bash load-dxfuse.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dac95d0f",
   "metadata": {},
   "source": [
    "Now we glue them together into a Pandas DataFrame, which we'll use to process all of the files. Note that if `testing == True`, then the notebook only processes the first 4 lines of the file manifest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d2e3eb1-cb69-41d8-8c17-64bd07072afc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#glue everything into a Pandas DataFrame, which we'll use to process files\n",
    "manifest = pd.DataFrame({\"bgen\": bgen_list, \"sample\": sample_list,\"index\":index_list, \"hdfs\": hdfs_list})  \n",
    "\n",
    "if(testing):\n",
    "    manifest = manifest.head(5)\n",
    "\n",
    "manifest = manifest.tail(-1)    \n",
    "    \n",
    "file_out = \"bgen_manifest.csv\"\n",
    "manifest.to_csv(file_out)\n",
    "\n",
    "#save file manifest to project sstorage\n",
    "dxpy.upload_local_file(filename=file_out, folder = \"/user/tladeras/index/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d788a64",
   "metadata": {},
   "source": [
    "Here's what the file manifest looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab3f709-83f9-44d4-ab00-4aa472fa4ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgen</th>\n",
       "      <th>sample</th>\n",
       "      <th>index</th>\n",
       "      <th>hdfs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file:///mnt/project//Bulk/Exome sequences/Popu...</td>\n",
       "      <td>file:///mnt/project//Bulk/Exome sequences/Popu...</td>\n",
       "      <td>ukb23159_c11_b0_v1.bgen</td>\n",
       "      <td>hdfs:///index/ukb23159_c11_b0_v1.bgen.idx2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file:///mnt/project//Bulk/Exome sequences/Popu...</td>\n",
       "      <td>file:///mnt/project//Bulk/Exome sequences/Popu...</td>\n",
       "      <td>ukb23159_c1_b0_v1.bgen</td>\n",
       "      <td>hdfs:///index/ukb23159_c1_b0_v1.bgen.idx2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file:///mnt/project//Bulk/Exome sequences/Popu...</td>\n",
       "      <td>file:///mnt/project//Bulk/Exome sequences/Popu...</td>\n",
       "      <td>ukb23159_c4_b0_v1.bgen</td>\n",
       "      <td>hdfs:///index/ukb23159_c4_b0_v1.bgen.idx2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file:///mnt/project//Bulk/Exome sequences/Popu...</td>\n",
       "      <td>file:///mnt/project//Bulk/Exome sequences/Popu...</td>\n",
       "      <td>ukb23159_c16_b0_v1.bgen</td>\n",
       "      <td>hdfs:///index/ukb23159_c16_b0_v1.bgen.idx2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                bgen  \\\n",
       "1  file:///mnt/project//Bulk/Exome sequences/Popu...   \n",
       "2  file:///mnt/project//Bulk/Exome sequences/Popu...   \n",
       "3  file:///mnt/project//Bulk/Exome sequences/Popu...   \n",
       "4  file:///mnt/project//Bulk/Exome sequences/Popu...   \n",
       "\n",
       "                                              sample                    index  \\\n",
       "1  file:///mnt/project//Bulk/Exome sequences/Popu...  ukb23159_c11_b0_v1.bgen   \n",
       "2  file:///mnt/project//Bulk/Exome sequences/Popu...   ukb23159_c1_b0_v1.bgen   \n",
       "3  file:///mnt/project//Bulk/Exome sequences/Popu...   ukb23159_c4_b0_v1.bgen   \n",
       "4  file:///mnt/project//Bulk/Exome sequences/Popu...  ukb23159_c16_b0_v1.bgen   \n",
       "\n",
       "                                         hdfs  \n",
       "1  hdfs:///index/ukb23159_c11_b0_v1.bgen.idx2  \n",
       "2   hdfs:///index/ukb23159_c1_b0_v1.bgen.idx2  \n",
       "3   hdfs:///index/ukb23159_c4_b0_v1.bgen.idx2  \n",
       "4  hdfs:///index/ukb23159_c16_b0_v1.bgen.idx2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81a80183-c22d-4cef-b4f8-17800f539eb8",
   "metadata": {},
   "source": [
    "Now we index each of the files by cycling over each BGEN file. This is currently saved in HDFS. We suggest storing the file manifest and the index files in a project so the BGEN files can be loaded in easily on subsequent runs.\n",
    "\n",
    "Note the BGEN files are in genome build `GRCh37`. If you want to use them in build 38, the BGEN files will need to be lifted over to the new genome build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ca6b78c-bc93-4a37-acb0-ccdcc15a67d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 07:32:24.282 Hail: INFO: Number of BGEN files indexed: 1             \n",
      "2023-04-28 07:33:37.080 Hail: INFO: Number of BGEN files indexed: 1             \n",
      "2023-04-28 07:34:04.005 Hail: INFO: Number of BGEN files indexed: 1             \n",
      "2023-04-28 07:34:32.800 Hail: INFO: Number of BGEN files indexed: 1             \n"
     ]
    }
   ],
   "source": [
    "for i, row in manifest.iterrows():\n",
    "    hl.index_bgen(path=row[\"bgen\"],\n",
    "                  index_file_map={row[\"bgen\"]:row[\"hdfs\"]},\n",
    "                  reference_genome=\"GRCh37\",\n",
    "                  contig_recoding=None,\n",
    "                  skip_invalid_loci=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "245fbe27",
   "metadata": {},
   "source": [
    "We can see the index files and their locations using `hdfs ds -ls`, which will list all of the files in `/index/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6767c572-c09d-4718-9beb-16a6e6b46940",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/cluster/hadoop/share/hadoop/common/lib/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/cluster/hadoop/share/hadoop/hdfs/lib/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\n",
      "drwxr-xr-x   - root supergroup          0 2023-04-28 07:32 /index/ukb23159_c11_b0_v1.bgen.idx2\n",
      "drwxr-xr-x   - root supergroup          0 2023-04-28 07:34 /index/ukb23159_c16_b0_v1.bgen.idx2\n",
      "drwxr-xr-x   - root supergroup          0 2023-04-28 07:33 /index/ukb23159_c1_b0_v1.bgen.idx2\n",
      "drwxr-xr-x   - root supergroup          0 2023-04-28 07:34 /index/ukb23159_c4_b0_v1.bgen.idx2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "hdfs dfs -ls /index/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cacfc0b",
   "metadata": {},
   "source": [
    "We should save these indexes into project storage."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3ac93ff",
   "metadata": {},
   "source": [
    "%%bash\n",
    "\n",
    "# download indexes to driver node\n",
    "hdfs dfs get /index/ .\n",
    "# upload the indexes to project storage\n",
    "dx upload -r index/*.idx2 --destination /user/tladeras/index/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af5ecc96-ddf1-447f-b176-39d7a8e8d00f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///mnt/project//Bulk/Exome sequences/Population level exome OQFE variants, BGEN format - final release/ukb23159_c11_b0_v1.sample'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = manifest[\"bgen\"].tolist()\n",
    "file_list\n",
    "\n",
    "sample_list = manifest[\"sample\"].tolist()[0]\n",
    "sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6c17ed1-e6fd-47d0-a691-83e164815bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file:///mnt/project//Bulk/Exome sequences/Population level exome OQFE variants, BGEN format - final release/ukb23159_c11_b0_v1.bgen': 'hdfs:///index/ukb23159_c11_b0_v1.bgen.idx2',\n",
       " 'file:///mnt/project//Bulk/Exome sequences/Population level exome OQFE variants, BGEN format - final release/ukb23159_c1_b0_v1.bgen': 'hdfs:///index/ukb23159_c1_b0_v1.bgen.idx2',\n",
       " 'file:///mnt/project//Bulk/Exome sequences/Population level exome OQFE variants, BGEN format - final release/ukb23159_c4_b0_v1.bgen': 'hdfs:///index/ukb23159_c4_b0_v1.bgen.idx2',\n",
       " 'file:///mnt/project//Bulk/Exome sequences/Population level exome OQFE variants, BGEN format - final release/ukb23159_c16_b0_v1.bgen': 'hdfs:///index/ukb23159_c16_b0_v1.bgen.idx2'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_dict = {f\"\" + row[\"bgen\"]:f\"\" + row[\"hdfs\"] for i, row in manifest.iterrows()}\n",
    "map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f0128b5-5fb1-41b9-945c-3e7aa555fe34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 07:35:25.048 Hail: INFO: Number of BGEN files parsed: 4\n",
      "2023-04-28 07:35:25.048 Hail: INFO: Number of samples in BGEN files: 469835\n",
      "2023-04-28 07:35:25.048 Hail: INFO: Number of variants across all BGEN files: 6666112\n"
     ]
    }
   ],
   "source": [
    "#build index file dictionary    \n",
    "\n",
    "#finally, import all bgen files\n",
    "mt = hl.import_bgen(file_list,\n",
    "                    entry_fields=['GT', 'GP'],\n",
    "                    sample_file = sample_list,\n",
    "                    n_partitions=None,\n",
    "                    block_size=None,\n",
    "                    variants=None,\n",
    "                    index_file_map = map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb74bf4c-1770-4eea-a15d-a27d9756af4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6666112, 469835)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585fad8-60d6-4962-9456-cf3b1d82aa1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
